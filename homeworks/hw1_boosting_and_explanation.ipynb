{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "celltoolbar": "Create Assignment",
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": false,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": true
    },
    "colab": {
      "name": "hw1_boosting_and_explanation.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/root-epifit/madmo-adv/blob/my_exercise/homeworks/hw1_boosting_and_explanation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JAyFp6Yjj5O-"
      },
      "source": [
        "# ДЗ №1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nbgrader": {
          "grade": false,
          "grade_id": "cell-86e0de040aac317a",
          "locked": true,
          "schema_version": 2,
          "solution": false
        },
        "id": "7kpv5agRjvY-"
      },
      "source": [
        "# Homework 1\n",
        "## Gradient boosting on temporal data and feature importances\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tUM8bx4PjvZG"
      },
      "source": [
        "Here we will work with widely known Human Actividy Recognition (HAR) dataset. Data is available at [UCI repository](https://archive.ics.uci.edu/ml/datasets/human+activity+recognition+using+smartphones).\n",
        "\n",
        "There are available both raw and preprocessed datasets. This time we will use the preprocessed one.\n",
        "\n",
        "Today we will work with [LightGBM](https://github.com/Microsoft/LightGBM) by Microsoft. It is one of the most popular frameworks these days that shows both great quality and performance.\n",
        "\n",
        "There are another great frameworks (listed below). However, we will stick to `LightGBM` for this task.\n",
        "* [Catboost](https://github.com/catboost/catboost) by Yandex. Novel framework by Yandex company tuned to deal well with categorical features.\n",
        "* [xgboost](https://github.com/dmlc/xgboost) by dlmc. The most famous framework which got very popular on kaggle.\n",
        "\n",
        "Some simple preprocessing is done for you. \n",
        "\n",
        "Your __ultimate target is to get familiar with one of the frameworks above__ and achieve at least 90% accuracy on test dataset and try to get some useful insights on the features the model paid attention to.\n",
        "\n",
        "__Please, use [`shap`](https://github.com/slundberg/shap) and interpret the generated plots (with a brief summary).__\n",
        "\n",
        "_Despite the main language of this notebook is English, feel free to write your thoughts in Russian._"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NzF1qs4vjvZI"
      },
      "source": [
        "## Part 0. Downloading and preprocessing\n",
        "\n",
        "The preprocessing is done for you. Let's take a look at the data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-11-01T21:00:39.321460Z",
          "start_time": "2021-11-01T21:00:39.072714Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xpy2PfmsjvZK",
        "outputId": "c9b1c1d9-63cd-4d71-e796-9514daab5d16"
      },
      "source": [
        "!wget -nc https://archive.ics.uci.edu/ml/machine-learning-databases/00240/UCI%20HAR%20Dataset.zip\n",
        "!unzip -u \"UCI HAR Dataset.zip\" \"UCI HAR Dataset/train/X_train.txt\" \"UCI HAR Dataset/train/y_train.txt\"\\\n",
        "\"UCI HAR Dataset/test/X_test.txt\" \"UCI HAR Dataset/test/y_test.txt\" \"UCI HAR Dataset/activity_labels.txt\""
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "File ‘UCI HAR Dataset.zip’ already there; not retrieving.\n",
            "\n",
            "Archive:  UCI HAR Dataset.zip\n",
            "caution: filename not matched:  UCI HAR Dataset/train/y_train.txtUCI HAR Dataset/test/X_test.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-66iHulqm7Zt",
        "outputId": "a1a52782-b4fa-4937-809d-2369df174a8f"
      },
      "source": [
        "!unzip -u \"UCI HAR Dataset.zip\" \"UCI HAR Dataset/train/X_train.txt\" \"UCI HAR Dataset/train/y_train.txt\""
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  UCI HAR Dataset.zip\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sWAS1Qn5neH_",
        "outputId": "45e10428-c121-4245-ffc4-78c5cc4a291a"
      },
      "source": [
        "!unzip -u \"UCI HAR Dataset.zip\" \"UCI HAR Dataset/test/X_test.txt\" \"UCI HAR Dataset/test/y_test.txt\" \"UCI HAR Dataset/activity_labels.txt\""
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  UCI HAR Dataset.zip\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vk329yNBxbnc"
      },
      "source": [
        "###### Проверяем загрузки"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CDqn3y2NxVRe",
        "outputId": "23a18bf5-9b7a-4d4c-8a39-06ca950a74af"
      },
      "source": [
        "! head -n 2 \"UCI HAR Dataset/train/X_train.txt\""
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  2.8858451e-001 -2.0294171e-002 -1.3290514e-001 -9.9527860e-001 -9.8311061e-001 -9.1352645e-001 -9.9511208e-001 -9.8318457e-001 -9.2352702e-001 -9.3472378e-001 -5.6737807e-001 -7.4441253e-001  8.5294738e-001  6.8584458e-001  8.1426278e-001 -9.6552279e-001 -9.9994465e-001 -9.9986303e-001 -9.9461218e-001 -9.9423081e-001 -9.8761392e-001 -9.4321999e-001 -4.0774707e-001 -6.7933751e-001 -6.0212187e-001  9.2929351e-001 -8.5301114e-001  3.5990976e-001 -5.8526382e-002  2.5689154e-001 -2.2484763e-001  2.6410572e-001 -9.5245630e-002  2.7885143e-001 -4.6508457e-001  4.9193596e-001 -1.9088356e-001  3.7631389e-001  4.3512919e-001  6.6079033e-001  9.6339614e-001 -1.4083968e-001  1.1537494e-001 -9.8524969e-001 -9.8170843e-001 -8.7762497e-001 -9.8500137e-001 -9.8441622e-001 -8.9467735e-001  8.9205451e-001 -1.6126549e-001  1.2465977e-001  9.7743631e-001 -1.2321341e-001  5.6482734e-002 -3.7542596e-001  8.9946864e-001 -9.7090521e-001 -9.7551037e-001 -9.8432539e-001 -9.8884915e-001 -9.1774264e-001 -1.0000000e+000 -1.0000000e+000  1.1380614e-001 -5.9042500e-001  5.9114630e-001 -5.9177346e-001  5.9246928e-001 -7.4544878e-001  7.2086167e-001 -7.1237239e-001  7.1130003e-001 -9.9511159e-001  9.9567491e-001 -9.9566759e-001  9.9165268e-001  5.7022164e-001  4.3902735e-001  9.8691312e-001  7.7996345e-002  5.0008031e-003 -6.7830808e-002 -9.9351906e-001 -9.8835999e-001 -9.9357497e-001 -9.9448763e-001 -9.8620664e-001 -9.9281835e-001 -9.8518010e-001 -9.9199423e-001 -9.9311887e-001  9.8983471e-001  9.9195686e-001  9.9051920e-001 -9.9352201e-001 -9.9993487e-001 -9.9982045e-001 -9.9987846e-001 -9.9436404e-001 -9.8602487e-001 -9.8923361e-001 -8.1994925e-001 -7.9304645e-001 -8.8885295e-001  1.0000000e+000 -2.2074703e-001  6.3683075e-001  3.8764356e-001  2.4140146e-001 -5.2252848e-002  2.6417720e-001  3.7343945e-001  3.4177752e-001 -5.6979119e-001  2.6539882e-001 -4.7787489e-001 -3.8530050e-001  3.3643943e-002 -1.2651082e-001 -6.1008489e-003 -3.1364791e-002  1.0772540e-001 -9.8531027e-001 -9.7662344e-001 -9.9220528e-001 -9.8458626e-001 -9.7635262e-001 -9.9236164e-001 -8.6704374e-001 -9.3378602e-001 -7.4756618e-001  8.4730796e-001  9.1489534e-001  8.3084054e-001 -9.6718428e-001 -9.9957831e-001 -9.9935432e-001 -9.9976339e-001 -9.8343808e-001 -9.7861401e-001 -9.9296558e-001  8.2631682e-002  2.0226765e-001 -1.6875669e-001  9.6323236e-002 -2.7498511e-001  4.9864419e-001 -2.2031685e-001  1.0000000e+000 -9.7297139e-001  3.1665451e-001  3.7572641e-001  7.2339919e-001 -7.7111201e-001  6.9021323e-001 -3.3183104e-001  7.0958377e-001  1.3487336e-001  3.0109948e-001 -9.9167400e-002 -5.5517369e-002 -6.1985797e-002 -9.9211067e-001 -9.9251927e-001 -9.9205528e-001 -9.9216475e-001 -9.9494156e-001 -9.9261905e-001 -9.9015585e-001 -9.8674277e-001 -9.9204155e-001  9.9442876e-001  9.9175581e-001  9.8935195e-001 -9.9445335e-001 -9.9993755e-001 -9.9995350e-001 -9.9992294e-001 -9.9229974e-001 -9.9693892e-001 -9.9224298e-001 -5.8985096e-001 -6.8845905e-001 -5.7210686e-001  2.9237634e-001 -3.6199802e-001  4.0554269e-001 -3.9006951e-002  9.8928381e-001 -4.1456048e-001  3.9160251e-001  2.8225087e-001  9.2726984e-001 -5.7237001e-001  6.9161920e-001  4.6828982e-001 -1.3107697e-001 -8.7159695e-002  3.3624748e-001 -9.5943388e-001 -9.5055150e-001 -9.5799295e-001 -9.4630524e-001 -9.9255572e-001 -9.5943388e-001 -9.9849285e-001 -9.5763740e-001 -2.3258164e-001 -1.7317874e-001 -2.2896660e-002  9.4831568e-002  1.9181715e-001 -9.5943388e-001 -9.5055150e-001 -9.5799295e-001 -9.4630524e-001 -9.9255572e-001 -9.5943388e-001 -9.9849285e-001 -9.5763740e-001 -2.3258164e-001 -1.7317874e-001 -2.2896660e-002  9.4831568e-002  1.9181715e-001 -9.9330586e-001 -9.9433641e-001 -9.9450037e-001 -9.9278399e-001 -9.9120847e-001 -9.9330586e-001 -9.9989188e-001 -9.9293370e-001 -8.6341476e-001  2.8308522e-001 -2.3730869e-001 -1.0543219e-001 -3.8212313e-002 -9.6895908e-001 -9.6433518e-001 -9.5724477e-001 -9.7505986e-001 -9.9155366e-001 -9.6895908e-001 -9.9928646e-001 -9.4976582e-001  7.2579035e-002  5.7251142e-001 -7.3860219e-001  2.1257776e-001  4.3340495e-001 -9.9424782e-001 -9.9136761e-001 -9.9314298e-001 -9.8893563e-001 -9.9348603e-001 -9.9424782e-001 -9.9994898e-001 -9.9454718e-001 -6.1976763e-001  2.9284049e-001 -1.7688920e-001 -1.4577921e-001 -1.2407233e-001 -9.9478319e-001 -9.8298410e-001 -9.3926865e-001 -9.9542175e-001 -9.8313297e-001 -9.0616498e-001 -9.9688864e-001 -9.8451927e-001 -9.3208200e-001 -9.9375634e-001 -9.8316285e-001 -8.8505422e-001 -9.9396185e-001 -9.9344611e-001 -9.2342772e-001 -9.7473271e-001 -9.9996838e-001 -9.9968911e-001 -9.9489148e-001 -9.9592602e-001 -9.8970889e-001 -9.8799115e-001 -9.4635692e-001 -9.0474776e-001 -5.9130248e-001 -1.0000000e+000 -1.0000000e+000 -1.0000000e+000  2.5248290e-001  1.3183575e-001 -5.2050251e-002  1.4205056e-001 -1.5068250e-001 -2.2054694e-001 -5.5873853e-001  2.4676868e-001 -7.4155206e-003 -9.9996279e-001 -9.9998650e-001 -9.9997907e-001 -9.9996244e-001 -9.9993222e-001 -9.9972512e-001 -9.9967039e-001 -9.9998582e-001 -9.9996867e-001 -9.9997686e-001 -9.9986966e-001 -9.9977613e-001 -9.9997115e-001 -9.9991925e-001 -9.9965680e-001 -9.9986046e-001 -9.9986695e-001 -9.9986301e-001 -9.9973783e-001 -9.9973220e-001 -9.9949261e-001 -9.9981364e-001 -9.9968182e-001 -9.9983940e-001 -9.9973823e-001 -9.9961197e-001 -9.9968721e-001 -9.9983863e-001 -9.9359234e-001 -9.9947584e-001 -9.9966204e-001 -9.9964230e-001 -9.9929341e-001 -9.9789222e-001 -9.9593249e-001 -9.9514642e-001 -9.9473990e-001 -9.9968826e-001 -9.9892456e-001 -9.9567134e-001 -9.9487731e-001 -9.9945439e-001 -9.9233245e-001 -9.8716991e-001 -9.8969609e-001 -9.9582068e-001 -9.9093631e-001 -9.9705167e-001 -9.9380547e-001 -9.9051869e-001 -9.9699279e-001 -9.9673689e-001 -9.9197516e-001 -9.9324167e-001 -9.9834907e-001 -9.9110842e-001 -9.5988537e-001 -9.9051499e-001 -9.9993475e-001 -9.9982048e-001 -9.9988449e-001 -9.9302626e-001 -9.9137339e-001 -9.9623962e-001 -1.0000000e+000 -1.0000000e+000 -1.0000000e+000  1.0000000e+000 -2.4000000e-001 -1.0000000e+000  8.7038451e-001  2.1069700e-001  2.6370789e-001 -7.0368577e-001 -9.0374251e-001 -5.8257362e-001 -9.3631005e-001 -5.0734474e-001 -8.0553591e-001 -9.9998649e-001 -9.9997960e-001 -9.9997478e-001 -9.9995513e-001 -9.9991861e-001 -9.9964011e-001 -9.9948330e-001 -9.9996087e-001 -9.9998227e-001 -9.9997072e-001 -9.9981098e-001 -9.9948472e-001 -9.9998083e-001 -9.9985189e-001 -9.9993261e-001 -9.9989993e-001 -9.9982444e-001 -9.9985982e-001 -9.9972751e-001 -9.9972876e-001 -9.9956707e-001 -9.9976524e-001 -9.9990021e-001 -9.9981490e-001 -9.9970980e-001 -9.9959608e-001 -9.9985216e-001 -9.9982210e-001 -9.9939988e-001 -9.9976559e-001 -9.9995846e-001 -9.9994951e-001 -9.9983850e-001 -9.9981351e-001 -9.9878054e-001 -9.9857783e-001 -9.9961968e-001 -9.9998359e-001 -9.9982812e-001 -9.9868068e-001 -9.9984416e-001 -9.9992792e-001 -9.8657442e-001 -9.8176153e-001 -9.8951478e-001 -9.8503264e-001 -9.7388607e-001 -9.9403493e-001 -9.8653085e-001 -9.8361636e-001 -9.9235201e-001 -9.8049843e-001 -9.7227092e-001 -9.9494426e-001 -9.9756862e-001 -9.8408510e-001 -9.9433541e-001 -9.8527621e-001 -9.9986371e-001 -9.9966608e-001 -9.9993462e-001 -9.9034389e-001 -9.9483569e-001 -9.9441158e-001 -7.1240225e-001 -6.4484236e-001 -8.3899298e-001 -1.0000000e+000 -1.0000000e+000 -1.0000000e+000 -2.5754888e-001  9.7947109e-002  5.4715105e-001  3.7731121e-001  1.3409154e-001  2.7337197e-001 -9.1261831e-002 -4.8434650e-001 -7.8285070e-001 -9.9986502e-001 -9.9993178e-001 -9.9997295e-001 -9.9997018e-001 -9.9993012e-001 -9.9995862e-001 -9.9992899e-001 -9.9998465e-001 -9.9986326e-001 -9.9996815e-001 -9.9993610e-001 -9.9995363e-001 -9.9986442e-001 -9.9996098e-001 -9.9945373e-001 -9.9997811e-001 -9.9999153e-001 -9.9999010e-001 -9.9996857e-001 -9.9980657e-001 -9.9834600e-001 -9.9896122e-001 -9.9961874e-001 -9.9998934e-001 -9.9993540e-001 -9.9838752e-001 -9.9964264e-001 -9.9997266e-001 -9.9995535e-001 -9.9997630e-001 -9.9990583e-001 -9.9998550e-001 -9.9993717e-001 -9.9975115e-001 -9.9907227e-001 -9.9992754e-001 -9.9995158e-001 -9.9990585e-001 -9.9989269e-001 -9.9944433e-001 -9.9994099e-001 -9.9995861e-001 -9.5215466e-001 -9.5613397e-001 -9.4887014e-001 -9.7432057e-001 -9.2572179e-001 -9.5215466e-001 -9.9828520e-001 -9.7327320e-001 -6.4637645e-001 -7.9310345e-001 -8.8436120e-002 -4.3647104e-001 -7.9684048e-001 -9.9372565e-001 -9.9375495e-001 -9.9197570e-001 -9.9336472e-001 -9.8817543e-001 -9.9372565e-001 -9.9991844e-001 -9.9136366e-001 -1.0000000e+000 -9.3650794e-001  3.4698853e-001 -5.1608015e-001 -8.0276003e-001 -9.8013485e-001 -9.6130944e-001 -9.7365344e-001 -9.5226383e-001 -9.8949813e-001 -9.8013485e-001 -9.9924035e-001 -9.9265553e-001 -7.0129141e-001 -1.0000000e+000 -1.2898890e-001  5.8615643e-001  3.7460462e-001 -9.9199044e-001 -9.9069746e-001 -9.8994084e-001 -9.9244784e-001 -9.9104773e-001 -9.9199044e-001 -9.9993676e-001 -9.9045792e-001 -8.7130580e-001 -1.0000000e+000 -7.4323027e-002 -2.9867637e-001 -7.1030407e-001 -1.1275434e-001  3.0400372e-002 -4.6476139e-001 -1.8445884e-002 -8.4124676e-001  1.7994061e-001 -5.8626924e-002\r\n",
            "  2.7841883e-001 -1.6410568e-002 -1.2352019e-001 -9.9824528e-001 -9.7530022e-001 -9.6032199e-001 -9.9880719e-001 -9.7491437e-001 -9.5768622e-001 -9.4306751e-001 -5.5785126e-001 -8.1840869e-001  8.4930787e-001  6.8584458e-001  8.2263681e-001 -9.8193011e-001 -9.9999130e-001 -9.9978838e-001 -9.9840537e-001 -9.9915036e-001 -9.7786550e-001 -9.4822478e-001 -7.1489166e-001 -5.0093000e-001 -5.7097906e-001  6.1162716e-001 -3.2954862e-001  2.8421321e-001  2.8459454e-001  1.1570542e-001 -9.0962529e-002  2.9431041e-001 -2.8121057e-001  8.5988430e-002 -2.2152694e-002 -1.6656535e-002 -2.2064350e-001 -1.3428663e-002 -7.2691890e-002  5.7938169e-001  9.6656113e-001 -1.4155127e-001  1.0937881e-001 -9.9741134e-001 -9.8944741e-001 -9.3163868e-001 -9.9788359e-001 -9.8961366e-001 -9.3324040e-001  8.9206031e-001 -1.6134256e-001  1.2258573e-001  9.8452014e-001 -1.1489334e-001  1.0276411e-001 -3.8342955e-001  9.0782890e-001 -9.7058275e-001 -9.7850045e-001 -9.9918838e-001 -9.9002851e-001 -9.4168540e-001 -1.0000000e+000 -1.0000000e+000 -2.1049361e-001 -4.1005552e-001  4.1385634e-001 -4.1756716e-001  4.2132499e-001 -1.9635929e-001  1.2534464e-001 -1.0556772e-001  1.0909013e-001 -8.3388211e-001  8.3427110e-001 -8.3418438e-001  8.3046390e-001 -8.3128389e-001 -8.6571108e-001  9.7438562e-001  7.4006709e-002  5.7711041e-003  2.9376633e-002 -9.9554814e-001 -9.8106363e-001 -9.9184570e-001 -9.9563201e-001 -9.7893801e-001 -9.9127664e-001 -9.9454467e-001 -9.7906823e-001 -9.9225735e-001  9.9257710e-001  9.9180836e-001  9.8853913e-001 -9.9139374e-001 -9.9995974e-001 -9.9963956e-001 -9.9984538e-001 -9.9386273e-001 -9.7943511e-001 -9.9338380e-001 -8.7509640e-001 -6.5536210e-001 -7.6738085e-001  4.8966215e-001  7.0997076e-002  3.6271450e-001  5.2730342e-001  1.4939565e-001  6.2925097e-002  3.7049343e-001  4.1354814e-001  1.2221568e-001  1.8061304e-001  4.7423999e-002  1.6657268e-001 -2.0877218e-001  8.4103799e-002 -2.6855390e-001 -1.6111620e-002 -8.3893777e-002  1.0058429e-001 -9.8311996e-001 -9.8904580e-001 -9.8912123e-001 -9.8689045e-001 -9.8903796e-001 -9.8918458e-001 -8.6490382e-001 -9.5356049e-001 -7.4587000e-001  8.3372106e-001  9.0810964e-001  8.2893499e-001 -9.8061310e-001 -9.9975577e-001 -9.9989731e-001 -9.9982242e-001 -9.9283276e-001 -9.8934472e-001 -9.9024019e-001  7.4693560e-003 -5.3115659e-001 -1.7744455e-001 -3.8768063e-001  1.7913763e-001  2.1078900e-001 -1.4025958e-001 -4.7031809e-002 -6.4949068e-002  1.1768661e-001  8.1691287e-002  4.2364040e-002 -1.4992836e-001  2.9261893e-001 -1.4942935e-001  4.6721243e-002 -2.5692940e-001  1.6939480e-001 -1.1050283e-001 -4.4818731e-002 -5.9242822e-002 -9.8987256e-001 -9.9729260e-001 -9.9385100e-001 -9.8987620e-001 -9.9749168e-001 -9.9377834e-001 -9.9194685e-001 -9.9771714e-001 -9.9492085e-001  9.9048601e-001  9.9712219e-001  9.9450312e-001 -9.9529844e-001 -9.9990775e-001 -9.9998972e-001 -9.9994591e-001 -9.9074179e-001 -9.9730134e-001 -9.9380781e-001 -6.0094453e-001 -7.4824724e-001 -6.0893213e-001 -1.9330757e-001 -6.7406458e-002  1.8561907e-001  4.1521811e-002  7.2352549e-002 -3.5377727e-002  1.7760636e-001  2.7498054e-002  1.8270272e-001 -1.6745740e-001  2.5325103e-001  1.3233386e-001  2.9385535e-001 -1.8075169e-002 -3.4333678e-001 -9.7928915e-001 -9.7605707e-001 -9.7824725e-001 -9.7871147e-001 -9.9533294e-001 -9.7928915e-001 -9.9948803e-001 -9.8124826e-001 -4.4187611e-001  8.1568632e-002 -1.0936606e-001  3.1175771e-001 -4.1167480e-001 -9.7928915e-001 -9.7605707e-001 -9.7824725e-001 -9.7871147e-001 -9.9533294e-001 -9.7928915e-001 -9.9948803e-001 -9.8124826e-001 -4.4187611e-001  8.1568632e-002 -1.0936606e-001  3.1175771e-001 -4.1167480e-001 -9.9125349e-001 -9.9169441e-001 -9.9271603e-001 -9.8866062e-001 -9.9120847e-001 -9.9125349e-001 -9.9984540e-001 -9.9348508e-001 -8.1992830e-001  4.5881205e-001 -2.4494134e-001  5.6139272e-002 -4.5834568e-001 -9.8068314e-001 -9.8375419e-001 -9.8200270e-001 -9.8471460e-001 -9.9155366e-001 -9.8068314e-001 -9.9972466e-001 -9.8285681e-001 -1.9289906e-001 -2.2531738e-001 -1.7059623e-002  1.5577724e-001  8.2575208e-002 -9.9512320e-001 -9.9610164e-001 -9.9583855e-001 -9.9654485e-001 -9.9200604e-001 -9.9512320e-001 -9.9996983e-001 -9.9481921e-001 -7.3072160e-001  2.0933413e-001 -1.7811256e-001 -1.0308433e-001 -4.3823965e-002 -9.9745072e-001 -9.7685173e-001 -9.7352267e-001 -9.9868026e-001 -9.7492981e-001 -9.5543811e-001 -9.9788967e-001 -9.7692389e-001 -9.6837677e-001 -9.9937173e-001 -9.7377026e-001 -9.4877678e-001 -9.9828058e-001 -9.9272090e-001 -9.8951355e-001 -9.8581162e-001 -9.9999084e-001 -9.9944988e-001 -9.9856912e-001 -9.9486488e-001 -9.8078362e-001 -9.8577466e-001 -1.0000000e+000 -9.0474776e-001 -7.5840851e-001  9.6774194e-002 -1.0000000e+000 -1.0000000e+000  2.7130855e-001  4.2863639e-002 -1.4309755e-002 -6.9254090e-001 -9.5404703e-001 -4.9709103e-002 -3.3197386e-001  5.6675367e-002 -2.8900144e-001 -9.9999619e-001 -9.9998175e-001 -9.9994400e-001 -9.9996988e-001 -9.9991885e-001 -9.9986573e-001 -9.9996507e-001 -9.9999945e-001 -9.9999394e-001 -9.9994898e-001 -9.9991401e-001 -9.9997661e-001 -9.9999213e-001 -9.9994590e-001 -9.9941662e-001 -9.9981329e-001 -9.9956858e-001 -9.9987368e-001 -9.9954892e-001 -9.9973714e-001 -9.9956575e-001 -9.9990532e-001 -9.9947352e-001 -9.9955418e-001 -9.9960203e-001 -9.9969530e-001 -9.9944422e-001 -9.9980416e-001 -9.9823460e-001 -9.9976916e-001 -9.9969223e-001 -9.9987487e-001 -9.9966565e-001 -9.9944828e-001 -9.9893018e-001 -9.9875435e-001 -9.9854556e-001 -9.9979176e-001 -9.9963116e-001 -9.9887752e-001 -9.9855336e-001 -9.9982213e-001 -9.9503222e-001 -9.8131147e-001 -9.8973975e-001 -9.9665235e-001 -9.8208394e-001 -9.9262682e-001 -9.9497670e-001 -9.8292946e-001 -9.9164143e-001 -9.9742453e-001 -9.8492321e-001 -9.9318704e-001 -9.9791682e-001 -9.8251860e-001 -9.8683843e-001 -9.8985094e-001 -9.9995965e-001 -9.9963962e-001 -9.9984664e-001 -9.9284336e-001 -9.8522065e-001 -9.9104933e-001 -1.0000000e+000 -1.0000000e+000 -1.0000000e+000 -3.2000000e-001 -1.2000000e-001 -3.2000000e-001  6.0851352e-001 -5.3675613e-002  6.3148268e-002 -6.3030495e-001 -9.1039449e-001 -4.1442354e-001 -8.5058640e-001 -6.5553468e-001 -9.1598691e-001 -9.9999635e-001 -9.9997967e-001 -9.9994892e-001 -9.9996834e-001 -9.9991010e-001 -9.9981369e-001 -9.9992027e-001 -9.9996071e-001 -9.9998672e-001 -9.9995600e-001 -9.9987671e-001 -9.9991409e-001 -9.9997443e-001 -9.9990582e-001 -9.9986103e-001 -9.9982717e-001 -9.9945649e-001 -9.9983029e-001 -9.9960932e-001 -9.9968546e-001 -9.9957615e-001 -9.9993695e-001 -9.9981738e-001 -9.9953247e-001 -9.9959516e-001 -9.9962567e-001 -9.9962988e-001 -9.9975933e-001 -9.9985891e-001 -9.9984650e-001 -9.9979487e-001 -9.9980092e-001 -9.9981932e-001 -9.9976916e-001 -9.9963701e-001 -9.9995450e-001 -9.9985190e-001 -9.9982733e-001 -9.9980005e-001 -9.9965102e-001 -9.9983501e-001 -9.9982668e-001 -9.7738671e-001 -9.9253003e-001 -9.8960578e-001 -9.8490434e-001 -9.8716807e-001 -9.8978468e-001 -9.7936121e-001 -9.9183683e-001 -9.8796514e-001 -9.8735382e-001 -9.8478644e-001 -9.9015077e-001 -9.8689184e-001 -9.9905355e-001 -9.9441373e-001 -9.8686870e-001 -9.9982491e-001 -9.9991146e-001 -9.9989205e-001 -9.8709935e-001 -9.9556375e-001 -9.8725448e-001 -6.1111189e-001 -7.6460301e-001 -7.5107966e-001 -1.0000000e+000 -1.0000000e+000 -1.0000000e+000 -4.8167435e-002 -4.0160791e-001 -6.8178329e-002 -4.5855331e-001 -7.9701355e-001  3.8756889e-001  1.4866483e-001 -1.5690927e-001 -4.5177589e-001 -9.9985087e-001 -9.9979432e-001 -9.9991309e-001 -9.9991816e-001 -9.9989636e-001 -9.9988528e-001 -9.9978419e-001 -9.9978237e-001 -9.9982986e-001 -9.9989878e-001 -9.9988283e-001 -9.9978339e-001 -9.9982832e-001 -9.9990802e-001 -9.9985638e-001 -9.9998846e-001 -9.9999570e-001 -9.9999416e-001 -9.9998608e-001 -9.9998455e-001 -9.9998002e-001 -9.9999002e-001 -9.9989660e-001 -9.9999447e-001 -9.9998604e-001 -9.9998167e-001 -9.9990259e-001 -9.9999165e-001 -9.9990889e-001 -9.9995940e-001 -9.9992807e-001 -9.9996632e-001 -9.9998549e-001 -9.9992637e-001 -9.9996147e-001 -9.9998312e-001 -9.9990171e-001 -9.9991776e-001 -9.9997539e-001 -9.9997110e-001 -9.9989434e-001 -9.9997104e-001 -9.8085662e-001 -9.7586576e-001 -9.7577688e-001 -9.7822635e-001 -9.8691082e-001 -9.8085662e-001 -9.9947194e-001 -9.8447923e-001 -8.1667357e-001 -1.0000000e+000 -4.4149887e-002 -1.2204037e-001 -4.4952188e-001 -9.9033549e-001 -9.9196029e-001 -9.8973198e-001 -9.9448884e-001 -9.8954882e-001 -9.9033549e-001 -9.9986688e-001 -9.9113389e-001 -1.0000000e+000 -8.4126984e-001  5.3206052e-001 -6.2487099e-001 -9.0015998e-001 -9.8829555e-001 -9.8332192e-001 -9.8265928e-001 -9.8632076e-001 -9.9182878e-001 -9.8829555e-001 -9.9981120e-001 -9.9397851e-001 -7.2068300e-001 -9.4871795e-001 -2.7195846e-001 -3.3631041e-001 -7.2001508e-001 -9.9585386e-001 -9.9639947e-001 -9.9544209e-001 -9.9686602e-001 -9.9443965e-001 -9.9585386e-001 -9.9998065e-001 -9.9454373e-001 -1.0000000e+000 -1.0000000e+000  1.5807454e-001 -5.9505094e-001 -8.6149931e-001  5.3476955e-002 -7.4345661e-003 -7.3262621e-001  7.0351059e-001 -8.4478760e-001  1.8028889e-001 -5.4316717e-002\r\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QTiMC2j3xolb",
        "outputId": "e37db9da-a766-43e2-c48c-e4f4a7806eb8"
      },
      "source": [
        "! head -n 2 \"UCI HAR Dataset/train/y_train.txt\""
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u6_fWj7mxv8L",
        "outputId": "4b4b6bf7-0c7e-4a79-a414-118fb9562d6d"
      },
      "source": [
        "! head \"UCI HAR Dataset/activity_labels.txt\""
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1 WALKING\n",
            "2 WALKING_UPSTAIRS\n",
            "3 WALKING_DOWNSTAIRS\n",
            "4 SITTING\n",
            "5 STANDING\n",
            "6 LAYING\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Sm-rTP-x6xN",
        "outputId": "5bd33dab-83c0-4a71-a1c6-18f1215388aa"
      },
      "source": [
        "! rm unique_columns*\n",
        "#! wget --no-check-certificate --content-disposition https://github.com/root-epifit/madmo-adv/blob/my_exercise/homeworks/unique_columns.txt\n",
        "! curl -LJ0 https://raw.githubusercontent.com/root-epifit/madmo-adv/my_exercise/homeworks/unique_columns.txt > unique_columns.txt\n",
        "print(\"File contents:\")\n",
        "! head -n 2 unique_columns.txt"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100  2050  100  2050    0     0   5924      0 --:--:-- --:--:-- --:--:--  5907\n",
            "File contents:\n",
            "0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200,201,202,203,204,206,207,208,209,210,211,212,226,227,228,229,230,232,233,234,235,236,237,238,239,240,241,242,243,245,246,247,248,249,250,251,252,253,254,255,256,258,259,260,261,262,263,264,265,266,267,268,269,270,271,272,273,274,275,276,277,278,279,280,281,282,283,284,285,286,287,288,289,290,291,292,293,294,295,296,297,298,299,300,301,302,303,304,305,306,307,308,309,310,311,312,313,314,315,316,317,318,319,320,321,322,323,324,325,326,327,328,329,330,331,332,333,334,335,336,337,338,339,340,341,342,343,344,345,346,347,348,349,350,351,352,353,354,355,356,357,358,359,360,361,362,363,364,365,366,367,368,369,370,371,372,373,374,375,376,377,378,379,380,381,382,383,384,385,386,387,388,389,390,391,392,393,394,395,396,397,398,399,400,401,402,403,404,405,406,407,408,409,410,411,412,413,414,415,416,417,418,419,420,421,422,423,424,425,426,427,428,429,430,431,432,433,434,435,436,437,438,439,440,441,442,443,444,445,446,447,448,449,450,451,452,453,454,455,456,457,458,459,460,461,462,463,464,465,466,467,468,469,470,471,472,473,474,475,476,477,478,479,480,481,482,483,484,485,486,487,488,489,490,491,492,493,494,495,496,497,498,499,500,501,502,503,504,505,506,508,509,510,511,512,513,514,515,516,517,518,519,521,522,523,524,525,526,527,528,529,530,531,532,534,535,536,537,538,539,540,541,542,543,544,545,547,548,549,550,551,552,553,554,555,556,557,558,559,560\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-11-01T21:02:20.491291Z",
          "start_time": "2021-11-01T21:02:20.266371Z"
        },
        "id": "eyRhByJfjvZN"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-11-01T21:02:41.967012Z",
          "start_time": "2021-11-01T21:02:38.548196Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iVGqO3myjvZO",
        "outputId": "6f9eef6e-e1d6-4529-8410-a9337e3b064b"
      },
      "source": [
        "X_train = np.genfromtxt(\"UCI HAR Dataset/train/X_train.txt\")\n",
        "y_train = np.genfromtxt(\"UCI HAR Dataset/train/y_train.txt\")\n",
        "\n",
        "X_test = np.genfromtxt(\"UCI HAR Dataset/test/X_test.txt\")\n",
        "y_test = np.genfromtxt(\"UCI HAR Dataset/test/y_test.txt\")\n",
        "\n",
        "activity_labels = {}\n",
        "with open(\"UCI HAR Dataset/activity_labels.txt\", \"r\") as file:\n",
        "    for line in file:\n",
        "        label, name = line.strip().split(\" \")\n",
        "        activity_labels[int(label)] = name\n",
        "\n",
        "activity_labels"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{1: 'WALKING',\n",
              " 2: 'WALKING_UPSTAIRS',\n",
              " 3: 'WALKING_DOWNSTAIRS',\n",
              " 4: 'SITTING',\n",
              " 5: 'STANDING',\n",
              " 6: 'LAYING'}"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oEKYdqB8n-CP",
        "outputId": "267b495f-4f15-4945-da79-2fca74dabfa3"
      },
      "source": [
        "X_train"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0.28858451, -0.02029417, -0.13290514, ..., -0.84124676,\n",
              "         0.17994061, -0.05862692],\n",
              "       [ 0.27841883, -0.01641057, -0.12352019, ..., -0.8447876 ,\n",
              "         0.18028889, -0.05431672],\n",
              "       [ 0.27965306, -0.01946716, -0.11346169, ..., -0.84893347,\n",
              "         0.18063731, -0.04911782],\n",
              "       ...,\n",
              "       [ 0.27338737, -0.01701062, -0.04502183, ..., -0.77913261,\n",
              "         0.24914484,  0.04081119],\n",
              "       [ 0.28965416, -0.01884304, -0.15828059, ..., -0.78518142,\n",
              "         0.24643223,  0.02533948],\n",
              "       [ 0.35150347, -0.01242312, -0.20386717, ..., -0.78326693,\n",
              "         0.24680852,  0.03669484]])"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-11-01T20:18:00.103956Z",
          "start_time": "2021-11-01T20:18:00.028869Z"
        },
        "id": "O5y-lxyzjvZP"
      },
      "source": [
        "print(X_train.shape)\n",
        "data_mean = X_train.mean(axis=0)\n",
        "data_std = X_train.std(axis=0)\n",
        "\n",
        "X_train = (X_train - data_mean) / data_std\n",
        "X_test = (X_test - data_mean) / data_std"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aO2e_1AdjvZR"
      },
      "source": [
        "The dataset has some duplicating features. File `unique_columns.txt` stores the indices of the unique ones. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-11-01T20:18:01.247829Z",
          "start_time": "2021-11-01T20:18:01.109806Z"
        },
        "id": "0izc56PbjvZT"
      },
      "source": [
        "unique_columns = np.genfromtxt(\"unique_columns.txt\", delimiter=\",\").astype(int)\n",
        "X_train_unique = X_train[:, unique_columns]\n",
        "X_test_unique = X_test[:, unique_columns]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DaoQGidPjvZU"
      },
      "source": [
        "PCA could be useful in this case. E.g."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u9vfy1VijvZV"
      },
      "source": [
        "from sklearn.decomposition import PCA"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sg1twdJtjvZW"
      },
      "source": [
        "pca = PCA(0.99)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_UQucsfujvZX"
      },
      "source": [
        "X_train_pca = pca.fit_transform(X_train_unique)\n",
        "X_test_pca = pca.transform(X_test_unique)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ell3ji9UjvZY"
      },
      "source": [
        "X_train_pca.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W0iZ6vUkjvZY"
      },
      "source": [
        "X_test_pca.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UVFGyS6jjvZZ"
      },
      "source": [
        "plt.scatter(X_train_pca[:1000, 0], X_train_pca[:1000, 1], c=y_train[:1000])\n",
        "plt.grid()\n",
        "plt.xlabel(\"Principal component 1\")\n",
        "plt.ylabel(\"Principal component 2\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9C8pYHvMjvZZ"
      },
      "source": [
        "plt.scatter(X_train_pca[:1000, 3], X_train_pca[:1000, 4], c=y_train[:1000])\n",
        "plt.grid()\n",
        "plt.xlabel(\"Principal component 4\")\n",
        "plt.ylabel(\"Principal component 5\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ppXRaeqwjvZa"
      },
      "source": [
        "## Part 1. Fit the model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aQoDF5-ZjvZa"
      },
      "source": [
        "Despite optimal parameters (e.g. for xgboost) can be found on the web, we still want you to approximate them by yourself.\n",
        "\n",
        "In this part just check some hyperparams by hand."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FqpG1iAqjvZb"
      },
      "source": [
        "# YOUR CODE HERE\n",
        "\n",
        "# Example: https://rpubs.com/burakh/har_xgb"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9zEODfj8jvZc"
      },
      "source": [
        "Please, write down your thoughts on the experiment results."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yMIDDLWcjvZc"
      },
      "source": [
        "## Part 2. Use hyper parameter tuning system\n",
        "\n",
        "Use [optuna](https://optuna.org/), [hyperopt](http://hyperopt.github.io/hyperopt/) or any other zero order optimizer to find optimal hyper param set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MURzqibYjvZc"
      },
      "source": [
        "# YOUR CODE HERE"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y6uotalcjvZd"
      },
      "source": [
        "### Part 3. Interpret the model predictions\n",
        "Despite you are free to use any approaches to interpret the model predictions, please use [`shap`](https://github.com/slundberg/shap) to build some plots (e.g. the ones we've seen on week02) and try to interpret them."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gIdsk17zjvZd"
      },
      "source": [
        "import shap\n",
        "\n",
        "\n",
        "# YOUR CODE HERE"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6rBvMmZIjvZd"
      },
      "source": [
        "_Your thoughts about the plots and model behaviour._"
      ]
    }
  ]
}