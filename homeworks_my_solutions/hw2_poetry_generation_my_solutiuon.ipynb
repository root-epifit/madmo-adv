{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": true
    },
    "colab": {
      "name": "hw2_poetry_generation_my_solutiuon.ipynb",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/root-epifit/madmo-adv/blob/my_exercise/homeworks_my_solutions/hw2_poetry_generation_my_solutiuon.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fTdFHaJkiK-q"
      },
      "source": [
        "# Homework 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V-_ANoJDiK-w"
      },
      "source": [
        "## Almost Shakespeare\n",
        "\n",
        "Let's try to generate some Shakespeare poetry using RNNs. The sonnets file is available in the notebook directory.\n",
        "\n",
        "Text generation can be designed in several steps:\n",
        "    \n",
        "1. Data loading\n",
        "2. Dictionary generation\n",
        "3. Data preprocessing\n",
        "4. Model (neural network) training\n",
        "5. Text generation (model evaluation)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DgcZLfvGiK-x"
      },
      "source": [
        "### Data loading"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qDy3n9k3iK-y"
      },
      "source": [
        "Shakespeare sonnets are awailable at this [link](http://www.gutenberg.org/ebooks/1041?msg=welcome_stranger). In addition, they are stored in the same directory as this notebook (`sonnetes.txt`).\n",
        "\n",
        "Simple preprocessing is already done for you in the next cell: all technical info is dropped.\n",
        "\n",
        "**Alternatively**\n",
        "\n",
        "You could use file `onegin.txt` with Russian texts or your natve language poetry to be able to assess results quality.\n",
        "\n",
        "**Note: In case of Onegin text you need to adjust reading procedure yourself!!!** (this file has a bit different format than `sonnets.txt`)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-11-11T13:32:31.898354Z",
          "start_time": "2021-11-11T13:32:31.627686Z"
        },
        "id": "WHY6SCEziK-y",
        "outputId": "2a5c5944-7e8d-42f8-c1ed-2c741e3bf47c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!wget -nc https://raw.githubusercontent.com/v-goncharenko/madmo-adv/55d929befa12370fc18109f5333f7cf000ea27ce/homeworks/sonnets.txt\n",
        "!wget -nc https://raw.githubusercontent.com/v-goncharenko/madmo-adv/55d929befa12370fc18109f5333f7cf000ea27ce/homeworks/onegin.txt"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2021-11-13 23:04:07--  https://raw.githubusercontent.com/v-goncharenko/madmo-adv/55d929befa12370fc18109f5333f7cf000ea27ce/homeworks/sonnets.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 119748 (117K) [text/plain]\n",
            "Saving to: ‘sonnets.txt’\n",
            "\n",
            "sonnets.txt         100%[===================>] 116.94K  --.-KB/s    in 0.01s   \n",
            "\n",
            "2021-11-13 23:04:07 (9.26 MB/s) - ‘sonnets.txt’ saved [119748/119748]\n",
            "\n",
            "--2021-11-13 23:04:07--  https://raw.githubusercontent.com/v-goncharenko/madmo-adv/55d929befa12370fc18109f5333f7cf000ea27ce/homeworks/onegin.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 262521 (256K) [text/plain]\n",
            "Saving to: ‘onegin.txt’\n",
            "\n",
            "onegin.txt          100%[===================>] 256.37K  --.-KB/s    in 0.02s   \n",
            "\n",
            "2021-11-13 23:04:08 (10.9 MB/s) - ‘onegin.txt’ saved [262521/262521]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-11-11T13:32:32.906264Z",
          "start_time": "2021-11-11T13:32:32.901604Z"
        },
        "id": "8EjPxvOYiK-0"
      },
      "source": [
        "with open(\"sonnets.txt\", \"r\") as iofile:\n",
        "    text = iofile.readlines()\n",
        "\n",
        "TEXT_START = 45\n",
        "TEXT_END = -368\n",
        "text = text[TEXT_START:TEXT_END]\n",
        "assert len(text) == 2616"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LE-_A1hwjAYj",
        "outputId": "3c20249c-76cf-4475-ff49-3df484b2ba91",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "text[:20]"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['  From fairest creatures we desire increase,\\n',\n",
              " \"  That thereby beauty's rose might never die,\\n\",\n",
              " '  But as the riper should by time decease,\\n',\n",
              " '  His tender heir might bear his memory:\\n',\n",
              " '  But thou, contracted to thine own bright eyes,\\n',\n",
              " \"  Feed'st thy light's flame with self-substantial fuel,\\n\",\n",
              " '  Making a famine where abundance lies,\\n',\n",
              " '  Thy self thy foe, to thy sweet self too cruel:\\n',\n",
              " \"  Thou that art now the world's fresh ornament,\\n\",\n",
              " '  And only herald to the gaudy spring,\\n',\n",
              " '  Within thine own bud buriest thy content,\\n',\n",
              " \"  And tender churl mak'st waste in niggarding:\\n\",\n",
              " '    Pity the world, or else this glutton be,\\n',\n",
              " \"    To eat the world's due, by the grave and thee.\\n\",\n",
              " '\\n',\n",
              " '  II\\n',\n",
              " '\\n',\n",
              " '  When forty winters shall besiege thy brow,\\n',\n",
              " \"  And dig deep trenches in thy beauty's field,\\n\",\n",
              " \"  Thy youth's proud livery so gazed on now,\\n\"]"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aTM9hv8wjEGU"
      },
      "source": [
        "with open(\"onegin.txt\", \"r\") as iofile:\n",
        "    otext = iofile.readlines()\n",
        "\n",
        "for i, token in enumerate(otext):\n",
        "    otext[i] = token.replace('\\t',' ')\n",
        "#TEXT_START = 45\n",
        "#TEXT_END = -368\n",
        "#text = text[TEXT_START:TEXT_END]\n",
        "assert len(otext) == 7088"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KaxbO4snjPzY",
        "outputId": "372a6c76-081e-4c48-d455-a88c7968e4b4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "len(otext)"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "7088"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pe6D52MfiK-1"
      },
      "source": [
        "In opposite to the in-class practice, this time we want to predict complex text. Let's reduce the complexity of the task and lowercase all the symbols.\n",
        "\n",
        "Now variable `text` is a list of strings. Join all the strings into one and lowercase it."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-11-11T16:16:31.398119Z",
          "start_time": "2021-11-11T16:16:31.380172Z"
        },
        "id": "SzMFpGMGiK-2"
      },
      "source": [
        "import string"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-11-11T13:32:52.502223Z",
          "start_time": "2021-11-11T13:32:52.421527Z"
        },
        "id": "Xd6vlpmxiK-3"
      },
      "source": [
        "# Join all the strings into one and lowercase it\n",
        "# Put result into variable text.\n",
        "\n",
        "# Your great code here\n",
        "\n",
        "assert len(text) == 100225, \"Are you sure you have concatenated all the strings?\"\n",
        "assert not any([x in set(text) for x in string.ascii_uppercase]), \"Uppercase letters are present\"\n",
        "print(\"OK!\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XZNfMwXXiK-4"
      },
      "source": [
        "Put all the characters, that you've seen in the text, into variable `tokens`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5blml8dviK-4"
      },
      "source": [
        "tokens = sorted(set(text))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nzVkrZfWiK-5"
      },
      "source": [
        "Create dictionary `token_to_idx = {<char>: <index>}` and dictionary `idx_to_token = {<index>: <char>}`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fRXTrZz3iK-5"
      },
      "source": [
        "# dict <index>:<char>\n",
        "# Your great code here\n",
        "\n",
        "# dict <char>:<index>\n",
        "# Your great code here"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h4XKHQwoiK-6"
      },
      "source": [
        "*Comment: in this task we have only 38 different tokens, so let's use one-hot encoding.*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PxWz73twiK-6"
      },
      "source": [
        "### Building the model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8rM5EY2viK-6"
      },
      "source": [
        "Now we want to build and train recurrent neural net which would be able to something similar to Shakespeare's poetry.\n",
        "\n",
        "Let's use vanilla RNN, similar to the one created during the lesson."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1jYnDZigiK-7"
      },
      "source": [
        "# Your code here"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LXvnzmSDiK-7"
      },
      "source": [
        "Plot the loss function (axis X: number of epochs, axis Y: loss function)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-VYYpYQQiK-8"
      },
      "source": [
        "# Your plot code here"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cVIFTDrxiK-8",
        "outputId": "93a96a7d-9142-4ba9-eb4c-6558a30c2030"
      },
      "source": [
        "# An example of generated text. There is no function `generate_text` in the code above.\n",
        "# print(generate_text(length=500, temperature=0.2))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "hide my will in thine?\n",
            "  shall will in of the simend that in my sime the seave the seave the sorll the soren the sange the seall seares and and the fart the wirl the seall the songh whing that thou hall will thoun the soond beare the with that sare the simest me the fart the wirl the songre the with thy seart so for shat so for do the dost the sing the sing the sing the soond canding the sack and the farling the wirl of sore sich and that with the seare the seall so fort the with the past the wirl the simen the wirl the sores the sare\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B_6xtWltiK-9"
      },
      "source": [
        "### More poetic model\n",
        "\n",
        "Let's use LSTM instead of vanilla RNN and compare the results."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4O4Oo7iziK-9"
      },
      "source": [
        "Plot the loss function of the number of epochs. Does the final loss become better?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bAf5g6FXiK--"
      },
      "source": [
        "# Your beautiful code here"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SLFmiiCGiK--"
      },
      "source": [
        "Generate text using the trained net with different `temperature` parameter: `(0.1, 0.2, 0.5, 1.0, 2.0)`.\n",
        "\n",
        "Evaluate the results visually, try to interpret them."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "92tYzk3piK--"
      },
      "source": [
        "# Text generation with different temperature values here"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QcRdVJmhiK--"
      },
      "source": [
        "### Saving and loading models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ShbfzrDQiK-_"
      },
      "source": [
        "Save the model to the disk, then load it and generate text.\n",
        "Follow guides from [this tutorial](https://pytorch.org/tutorials/beginner/saving_loading_models.html).\n",
        "\n",
        "You need to use `Save/Load state_dict (Recommended)` section aka save state dict."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0TQuZ-DxiK-_"
      },
      "source": [
        "# Saving and loading code here"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GfLglxI2iK-_"
      },
      "source": [
        "## Additional materials on topic\n",
        "\n",
        "1. [Andrew Karpathy blog post about RNN.](http://karpathy.github.io/2015/05/21/rnn-effectiveness/)\\\n",
        "There are several examples of genration: Shakespeare texts, Latex formulas, Linux Sourse Code and children names.\n",
        "2. <a href='https://github.com/karpathy/char-rnn'> Repo with char-rnn code </a>\n",
        "3. Cool repo with [PyTorch examples](https://github.com/spro/practical-pytorch`)"
      ]
    }
  ]
}